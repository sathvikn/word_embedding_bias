{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and Word Embeddings (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first Jupyter Notebook complementing my blog post: \n",
    "\n",
    "A very basic understanding of probability and linear algebra will be helpful, but no machine learning/natural language processing experience is needed to understand these notebooks. Please contact me if you think a certain concept needs to be clarified!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are word embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand word embeddings, a key paradigm in the natural language processing (NLP) community that we need to adopt is the idea of _text as data_. Once we treat a piece of text as data, we are able to use mathematical and statistical machine learning models to analyze this text.\n",
    "\n",
    "Before word embeddings were developed, there were other methods used for representing a word as a _vector_ of real numbers, but the advantage of embeddings is that they are _distributed word representations_. This means that a machine learning model does not to use \"one-hot encodings,\" where a word's vector is equal to the size of the entire vocabulary and every entry is equal to 0, except the one corresponding to the word, which is a 1. Instead, the model uses the _distributional hypothesis_, a term in linguistics that essentially states that a word's meaning is based on its context, so words that get mentioned in the same contexts usually have similar vectors. It can be argued that many of the recent advances in using computationally intensive neural networks for NLP tasks in the past 5-8 years, like machine translation and conversation agents, have happened due to the ability of word embeddings to capture a richer representation of textual data.\n",
    "\n",
    "There are a couple algorithms to learn embeddings from a _training corpus_, and their authors have made the results of training their models on certain corpora open-source. The model we'll use here is _Globalized Vectors for Word Representation_ [(Pennington, Socher, and Manning, 2014)](https://nlp.stanford.edu/projects/glove/), or GloVe. Essentially, GloVe uses a co-occurrence matrix, where the rows and columns are represented by words, and the entries depend on how likely a word is to appear in the context of another word, in other words, through Bayes's rule. In addition to probabilistic methods, the values of the embeddings are \"learned\" through matrix factorization methods. The other major algorithm to generate word embeddings is known as _Word2Vec_ ([Mikolov et al, 2013](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)), in which the embeddings are learned through neural networks. \n",
    "\n",
    "I chose to use GloVe over Word2Vec for this investigation because it is much easier to interact with the data, available through text files rather than binary files, and implement my own functions to learn about the embeddings. These embeddings were trained on Wikipedia and newswire text, and can be downloaded [here](http://nlp.stanford.edu/data/glove.6B.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfacing with Pre-Trained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we read in the data, and create a list of words contained in the embeddings, a dictionary mapping words to vectors, and a matrix of all the vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('glove.6B/glove.6B.100d.txt', 'r') \n",
    "vocab = []\n",
    "embeddings = {}\n",
    "matrix = []\n",
    "for line in f:\n",
    "    split_line = line.split()\n",
    "    word = split_line[0]\n",
    "    vector = np.asarray([float(i) for i in split_line[1:]])\n",
    "    embeddings.update({word:vector})\n",
    "    vocab.append(word)\n",
    "    matrix.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expressed in the blog post, whether an analogy gets successfully encoded in an embedding is often used as a way to verify if the model is correct.  We use the definition from [Levy, Goldberg (2014)](http://www.aclweb.org/anthology/W14-1618) when evaluating analogies. The canonical example is $queen - king \\approx woman - man$, where $queen$ is the unknown vector.\n",
    "\n",
    "We solve the analogy as follows(where $v$ is a word in the vocabulary, $V$, and $cos$ represents cosine similarity, a term we'll discuss later on): $$argmax_{v \\in V}(cos(v, woman - man + king)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(word, relation, k = 4, return_list = False):\n",
    "    \"\"\"Takes in a target word, a list of two words expressing a relation,\n",
    "    an integer denoting the amount of values that should be returned, and whether a list of words should be returned,\n",
    "    or only the first item. k is set to 4 by default, in the case that the target word and the relation words\n",
    "    answer the analogy.\n",
    "    Returns a list of words of length [k - 3, k] that satisfy the analogy in order of decreasing cosine similarity\"\"\"\n",
    "    if [i for i in [word, relation[0], relation[1]] if i not in embeddings]:\n",
    "        raise ValueError(\"Word must be in vocabulary\")\n",
    "    result_vector = embeddings[relation[0]] - embeddings[relation[1]] + embeddings[word]\n",
    "    nearest_indices = k_nearest_vectors(k, matrix, [result_vector])[0]\n",
    "    closest_words = [vocab[i] for i in nearest_indices if vocab[i] != word and vocab[i] not in relation]\n",
    "    if return_list:\n",
    "        return closest_words\n",
    "    else:\n",
    "        return closest_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following helper function to reduce the search space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_vectors(k, mtx, candidate_vector):\n",
    "    \"\"\"Takes in an integer value(k), a matrix (2D list) of all the vectors, and the vector (list) we want to compare.\n",
    "    Returns an array of length k for indices of the most similar word vectors, and the cosine similarities of these vectors \"\"\"\n",
    "    cos_similarities = cosine_similarity(mtx, candidate_vector).flatten()\n",
    "    k_sorted = np.flip(np.argsort(cos_similarities)[-k:], axis = 0)\n",
    "    cos_sorted = np.flip(np.sort(cos_similarities), axis = 0)[:k]\n",
    "    return k_sorted, cos_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following test tells us our helper function is correct: the item with the highest cosine similarity to a given word in the dataset will be the word itself. Because the function returns a list of indices, we check if the index corresponds most to the word we are checking by looking at its position in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index('woman') == k_nearest_vectors(5, matrix, [embeddings['woman']])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple analogies to make sure our evaluation function is working properly. We'll start with the example: \"woman\" is to \"man\" as \"queen\" is to \"king.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('king', ['woman', 'man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings can also reveal details like grammatical properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harder'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('hard', ['better', 'good']) #comparative adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ducks'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('duck', ['men', 'man']) #singular/plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'their'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('they', ['his', 'he']) #possessive forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can also help us answer questions about the world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beijing'"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('china', ['moscow', 'russia']) #capitals of countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gda≈Ñsk'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('danzig', ['mumbai', 'bombay']) #former names of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asia'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('japan', ['europe', 'germany']) #country-continent mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, embeddings can also reveal problematic *biases* in language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('nurse', ['man', 'doctor']) #gender based on occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('criminal', ['white', 'police']) #racial stereotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'islamic'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('terrorist', ['christianity', 'lawful']) #religious stereotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to figure out why this is the case by looking at some of the mathematical properties of the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, let's try to visualize our data. How exactly will this work, if each embedding is represented by a $[1 \\times 100]$ vector? We turn to _principal component analysis_, a technique used for _dimensionality reduction_, in order to create a 2D representation of the data. \n",
    "\n",
    "Don't worry too much if this term is new! PCA basically compresses all the information captured in our dataset into vectors called principal components. Each principle component explains a certain percentage of the _variance_, or spread, of our data. We're going to specify that it needs 2 components, because we're going to make a plot on an x-y plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91288564, 0.51800902])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components = 2)\n",
    "mtx_2d = pca.fit_transform(matrix)\n",
    "embeddings_2d = {vocab[i]:mtx_2d[i] for i in np.arange(len(vocab))}\n",
    "#Our x-coordinate explains a little over 90% of the variance, and the y-coordinate explains a little over half.\n",
    "pca.explained_variance_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now write a function to plot word embeddings on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_embeddings(word_lst, embedding_dict, dot_color, labels = True):\n",
    "    coords = [embedding_dict[word] for word in word_lst]\n",
    "    extract_coords = lambda tuple_index: [c[tuple_index] for c in coords] \n",
    "    x = extract_coords(0)\n",
    "    y = extract_coords(1)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x, y, color = dot_color)\n",
    "    if labels:\n",
    "        for i in np.arange(len(word_lst)):\n",
    "            ax.annotate(word_lst[i], (x[i] + 0.05, y[i] + 0.05))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each graph, I tried doing the \"base\" relation, one true relation, and one false relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45817038417787165, 1.55)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender_ax = plot_embeddings(['man', 'woman', 'queen', 'king', 'engineer', 'housewife'], embeddings_2d, 'blue') \n",
    "#base: man-woman, true: queen - king, false: engineer - housewife\n",
    "gender_ax.set_xlim(right=5)\n",
    "gender_ax.set_ylim(top = 1.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06473013401858435, 1.3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "race_ax = plot_embeddings(['criminal', 'police', 'black', 'white', 'guilty', 'innocent'], embeddings_2d, 'orange') \n",
    "#base: innocent-guilty, true: police - criminal, false: black - white\n",
    "\n",
    "race_ax.set_xlim(right= 5.6)\n",
    "race_ax.set_ylim(top = 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3662851480117592, 1.7)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "religion_ax = plot_embeddings(['islam', 'christianity', 'terrorist', 'lawful', 'eid', 'pentecost'], embeddings_2d, 'green')\n",
    "#base: islam-christianity, true: eid - pentecost, false: terrorist - lawful\n",
    "religion_ax.set_xlim(right= 4.2)\n",
    "religion_ax.set_ylim(top = 1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully we were able to see some of the relationships between a couple of our data points! Let's now look at some mathematical properties of the embeddings. The first thing we can do is look at cosine similarity, which gives us the cosine of the angle between two vectors. The reason we use it over a spatial measure like Euclidean distance is because we're really trying to look at the relationship _between_ words. \n",
    "\n",
    "Although \"man\" and \"engineer\" might be extremely far from each other in our vector space, the relationship between the vectors for \"engineer\" and \"woman\" might be different. Additionally, the words for \"doctor\" and \"nurse\" appear much closer than other words based on gender, possibly pointing to the amount of male nurses and female doctors mentioned in the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_words(target, relation):\n",
    "    target_embedding = embeddings['target']\n",
    "    return [(relation[0], cosine_similarity([target_embedding], [embeddings[relation[0]]])[0]),\n",
    "             (relation[1], cosine_similarity([target_embedding], [embeddings[relation[1]]])[0])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', array([0.42758992])), ('woman', array([0.33741925]))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_words('engineer', ['man', 'woman']) #gender stereotypes in engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('asian', array([0.42330513])), ('african-american', array([0.02642636]))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_words('engineer', ['asian', 'african-american']) #model minority myth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('christianity', array([0.17068761])), ('islam', array([0.32167268]))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_words('terrorist', ['christianity', 'islam']) #islam being associated with terrorism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('black', array([0.32004993])), ('white', array([0.33585093]))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_words('criminal', ['black', 'white']) #races of criminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see too much of a difference for the last relation, but see evident gaps in the cosine similarity among the other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing for Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll go beyond analogies and apply cosine similarity and other operations to look at the entire dataset. \n",
    "\n",
    "In order to reduce the dimensionality of our search space, we're only going to consider words that describe people. The WordNet database organizes words based on semantics, so we're going to look at the _hyponyms_(words that could be subcategories of a given word) of the word \"person.\" In WordNet, the entry for a word corresponds to a _synset_, which is a set of _senses_, or contexts, a word could be mentioned in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The senses of \"person\" are listed [here](http://wordnetweb.princeton.edu/perl/webwn?s=person&sub=Search+WordNet&o2=&o0=1&o8=1&o1=1&o7=&o5=&o9=&o6=&o3=&o4=&h=), we will use the first one.\n",
    "\n",
    "Although using built-in tools that perform tasks like named-entity recognition would be useful for this task, these are statistical/neural models that often require the word to be in a sentence. We could also look at databases that contain named entities to get rid of proper nouns, but because many common words are also proper nouns(i.e. the Apple corporation, surnames like Smith and Trump), this wouldn't be the most accurate method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyponyms(synset):\n",
    "    \"\"\"Get all words that are considered subcategories, or hyponyms of a particular noun.\n",
    "    Takes in a WordNet Synset object, returns a set of words that are part of that synset\"\"\"\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym)) #Gets union of all the hyponyms of the word\n",
    "    hyponyms = hyponyms | set(synset.hyponyms())\n",
    "    return hyponyms\n",
    "\n",
    "types_of_people = {synset.name().split('.')[0] for synset in get_hyponyms(wn.synset('person.n.01'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also hard-code a list of gender-specific words, and add additional logic to a function to tell us if a word is specific to the male or female gender using the following lists from Danielle Sucher's [repo](https://github.com/DanielleSucher/Jailbreak-the-Patriarchy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Danielle Sucher's https://github.com/DanielleSucher/Jailbreak-the-Patriarchy\n",
    "male_words=set(['guy','spokesman','chairman',\"men's\",'men','him',\"he's\",'his',\n",
    "                'boy','boyfriend','boyfriends','boys','brother','brothers','dad','dads','dude','father','fathers',\n",
    "                'fiance','gentleman','gentlemen','god','grandfather','grandpa','grandson','groom','he','himself',\n",
    "                'husband','husbands','king','male','man','mr','nephew','nephews','priest','prince','son',\n",
    "                'sons','uncle','uncles','waiter','widower','widowers'])\n",
    "female_words=set(['heroine','spokeswoman','chairwoman',\"women's\",\n",
    "                  'actress','women',\"she's\",'her','aunt','aunts','bride',\n",
    "                  'daughter','daughters','female','fiancee','girl','girlfriend','girlfriends','girls',\n",
    "                  'goddess','granddaughter','grandma','grandmother','herself','ladies','lady','lady','mom',\n",
    "                  'moms','mother','mothers','mrs','ms','niece','nieces','priestess','princess','queens','she',\n",
    "                  'sister','sisters','waitress','widow','widows','wife','wives','woman'])\n",
    "def gender_neutral(word):\n",
    "    \"\"\"Takes in a word and returns True if the word does not belong to \"\"\"\n",
    "    return (word not in male_words) and (word not in female_words) and (not word.endswith('man')) and (not word.endswith('woman'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Finding the Closest Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our embeddings for people, let's look at the most similar words to a target word, like \"man.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_persons(k, word, gender_bias = False):\n",
    "    #Here, we can use the cosine similarity array returned by k_nearest_vectors!\n",
    "    \"\"\"Takes in an integer, a word, and a flag if we're detecting gender bias to only include gender neutral words.\n",
    "    Returns a list of tuples in the following format \n",
    "    (word, cosine similarity to target, numerical rank of word with respect to target).\n",
    "    Because k_nearest_vectors outputs all types of vectors, the output will not have length k\"\"\"\n",
    "    k_nearest = k_nearest_vectors(k, matrix, [embeddings[word]])\n",
    "    people_tuples = [(vocab[k_nearest[0][i]], k_nearest[1][i], i) for i in np.arange(len(k_nearest[0])) \n",
    "            if vocab[k_nearest[0][i]] in types_of_people and vocab[k_nearest[0][i]] != word]\n",
    "    if gender_bias:\n",
    "        people_tuples = [t for t in people_tuples if gender_neutral(t[0])]\n",
    "    return people_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 0.7371696782207191, 7),\n",
       " ('friend', 0.7170529706205984, 17),\n",
       " ('victim', 0.7082503974622372, 22),\n",
       " ('hand', 0.6704838539317455, 43),\n",
       " ('child', 0.6682647764797975, 47),\n",
       " ('hero', 0.6675072516075166, 50),\n",
       " ('soldier', 0.6572092481205023, 62),\n",
       " ('face', 0.6513383454136314, 73),\n",
       " ('shot', 0.6459691581360679, 89),\n",
       " ('character', 0.6392505276292051, 101),\n",
       " ('black', 0.6352095962184885, 113),\n",
       " ('back', 0.6348550425102408, 115),\n",
       " ('great', 0.6293664692090448, 131),\n",
       " ('head', 0.6289984883078916, 133),\n",
       " ('killer', 0.6218355513843233, 150),\n",
       " ('suspect', 0.6215987415548052, 152),\n",
       " ('lover', 0.6208189942315082, 156),\n",
       " ('sort', 0.6158453620191224, 168),\n",
       " ('best', 0.6132266626021035, 172),\n",
       " ('case', 0.6110351880748324, 181),\n",
       " ('doctor', 0.6092161526918836, 188),\n",
       " ('second', 0.6075386022692146, 197),\n",
       " ('name', 0.5984954299386631, 227),\n",
       " ('star', 0.5968591434323185, 232),\n",
       " ('self', 0.5865607346224554, 273),\n",
       " ('baby', 0.5813004476031609, 292),\n",
       " ('cousin', 0.5811990645794511, 293),\n",
       " ('witness', 0.5807797929311391, 298)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_persons(300, 'man', gender_bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('victim', 0.6407717678973269, 14),\n",
       " ('child', 0.6294301260530981, 16),\n",
       " ('lover', 0.5692697895600373, 28),\n",
       " ('nurse', 0.5646969077183875, 30),\n",
       " ('friend', 0.564160484551198, 31),\n",
       " ('life', 0.5593739976157563, 33),\n",
       " ('soldier', 0.5581014336367704, 36),\n",
       " ('worker', 0.5545941541036009, 39),\n",
       " ('prostitute', 0.5371960748744896, 47),\n",
       " ('baby', 0.5344769899519755, 52),\n",
       " ('teacher', 0.5338314430177431, 53),\n",
       " ('housewife', 0.531849122933435, 54),\n",
       " ('doctor', 0.5293920825671159, 57),\n",
       " ('married', 0.5071280346270718, 82),\n",
       " ('birth', 0.5048731795435029, 87),\n",
       " ('patient', 0.48858733901003293, 118),\n",
       " ('black', 0.4878013038637666, 119),\n",
       " ('attacker', 0.4832373010057014, 140),\n",
       " ('witness', 0.47893709378973437, 153),\n",
       " ('athlete', 0.47582035817977636, 164),\n",
       " ('case', 0.47466957549254385, 169),\n",
       " ('lawyer', 0.4741562391662266, 170),\n",
       " ('stranger', 0.47383268845460397, 173),\n",
       " ('student', 0.4716806493229572, 180),\n",
       " ('politician', 0.47160690569794794, 181),\n",
       " ('journalist', 0.4713477539783594, 184),\n",
       " ('maid', 0.47077156215759614, 187),\n",
       " ('shot', 0.47067472219032136, 188),\n",
       " ('face', 0.47060019307594303, 189),\n",
       " ('servant', 0.4702198434804906, 193),\n",
       " ('blond', 0.47008655118478365, 194),\n",
       " ('colleague', 0.4684097023032704, 199)]"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_persons(200, 'woman', gender_bias = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For \"man\" and \"woman\", we see that there are a lot of gender-specific words like \"son\" and \"daughter,\" but we also see some trends like \"prostitute\" and \"teacher\" being much closer to the vector for \"woman,\" when we see words like \"soldier\" and \"hero\" being closer to the vector for \"man.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('journalist', 0.5365671755406114, 4),\n",
       " ('resident', 0.5335940780111741, 5),\n",
       " ('american', 0.524323772697212, 7),\n",
       " ('immigrant', 0.5149044179025113, 9),\n",
       " ('canadian', 0.5087608372053418, 10),\n",
       " ('businessman', 0.4919954582587013, 15),\n",
       " ('ordinary', 0.49197911067484723, 16),\n",
       " ('politician', 0.49193664604583437, 17),\n",
       " ('lawyer', 0.4886279012698642, 18),\n",
       " ('advocate', 0.4798776509638012, 21),\n",
       " ('soldier', 0.4706849981014689, 23),\n",
       " ('diplomat', 0.47035736040449666, 24),\n",
       " ('woman', 0.4632373958648325, 29),\n",
       " ('fellow', 0.4516985015782866, 35),\n",
       " ('worker', 0.4481144856053686, 37),\n",
       " ('student', 0.443539956291243, 41),\n",
       " ('member', 0.4352997475956328, 46),\n",
       " ('man', 0.43399099844859074, 50),\n",
       " ('jew', 0.42736058974833313, 58)]"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_persons(60, 'citizen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('migrant', 0.6586581622064355, 2),\n",
       " ('worker', 0.5467345173802629, 7),\n",
       " ('haitian', 0.5171931693127529, 10),\n",
       " ('citizen', 0.5149044179025113, 11),\n",
       " ('refugee', 0.4999778243758676, 19),\n",
       " ('mexican', 0.4850413018421284, 21),\n",
       " ('african-american', 0.4609086396751774, 35),\n",
       " ('child', 0.45092261580120474, 42),\n",
       " ('laborer', 0.44883905259640056, 46),\n",
       " ('jew', 0.43974927338906955, 53),\n",
       " ('native', 0.43409641745666205, 58),\n",
       " ('slave', 0.4277706757138491, 67),\n",
       " ('peasant', 0.42618831955368186, 69),\n",
       " ('mother', 0.41915443702011984, 76),\n",
       " ('settler', 0.41906893504267106, 77),\n",
       " ('ethnic', 0.4190071505342275, 78),\n",
       " ('hmong', 0.41789418111914434, 81),\n",
       " ('homeless', 0.41577220439169393, 87),\n",
       " ('gypsy', 0.4137312893354037, 89),\n",
       " ('cuban', 0.41006546518145714, 94)]"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_persons(100, 'immigrant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For \"citizen\" and \"immigrant,\" we see terms that are biased toward professional occupations and poverty, respectively. \"Immigrant\" yielded more nationalities than \"citizen.\" Inputting specific nationalities only outputted vectors for other nationalities (i.e. \"american\" is near \"canadian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('muslim', 0.63936552999292, 4),\n",
       " ('religious', 0.6055856303162457, 6),\n",
       " ('prophet', 0.5690866955013705, 10),\n",
       " ('fundamentalist', 0.5615563148585314, 12),\n",
       " ('imam', 0.5159405941281745, 24),\n",
       " ('extremist', 0.5112426507672221, 26),\n",
       " ('sufi', 0.4988681944633398, 33),\n",
       " ('radical', 0.4985477790676014, 34),\n",
       " ('wahhabi', 0.47694639943682626, 53),\n",
       " ('shiite', 0.4716709054408388, 58),\n",
       " ('militant', 0.4659725130662824, 60),\n",
       " ('islamist', 0.46129436122721695, 64),\n",
       " ('cleric', 0.4462623660480373, 72),\n",
       " ('christian', 0.43232337579933255, 87),\n",
       " ('arab', 0.42549909536029623, 97)]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_persons(100, 'islam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('religious', 0.5704454681564426, 23),\n",
       " ('christian', 0.5650218802997707, 26),\n",
       " ('pagan', 0.5551570324668353, 28),\n",
       " ('roman', 0.48583317469927545, 65),\n",
       " ('catholic', 0.4855725548429508, 66),\n",
       " ('convert', 0.48535247510562557, 67),\n",
       " ('protestant', 0.4639060874298178, 84),\n",
       " ('byzantine', 0.4615717798917954, 86),\n",
       " ('pentecostal', 0.4601624667361376, 90)]"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_persons(100, 'christianity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with religious words, the vector for \"islam\" is also close to words like \"militant\" and \"extremist,\" but this trend does not appear for other religions like Christianity. As a whole, this approach allows us to see some trends, but nothing too specific. In the next notebook, we'll learn about at an alternative way to quantify bias, implement it, and visualize our results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datascience]",
   "language": "python",
   "name": "conda-env-datascience-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
